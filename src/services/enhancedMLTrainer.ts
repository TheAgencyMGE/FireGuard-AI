// Enhanced ML Trainer for Wildfire Prediction
// Trains multiple models using comprehensive CSV data and saves them as pretrained models

import * as tf from '@tensorflow/tfjs';
import DataProcessor, { TrainingDataset, ProcessedFireData } from './dataProcessor';

export interface ModelTrainingResult {
  modelName: string;
  accuracy: number;
  loss: number;
  trainingTime: number;
  modelSize: number;
  features: string[];
  metadata: {
    totalSamples: number;
    trainingSamples: number;
    validationSamples: number;
    testSamples: number;
    fireSamples: number;
    noFireSamples: number;
  };
}

export interface TrainedModel {
  name: string;
  model: tf.LayersModel;
  accuracy: number;
  features: string[];
  version: string;
  trainingDate: string;
}

class EnhancedMLTrainer {
  private static instance: EnhancedMLTrainer;
  private dataProcessor: DataProcessor;
  private trainedModels: Map<string, TrainedModel> = new Map();
  private isInitialized = false;

  private constructor() {
    this.dataProcessor = DataProcessor.getInstance();
  }

  public static getInstance(): EnhancedMLTrainer {
    if (!EnhancedMLTrainer.instance) {
      EnhancedMLTrainer.instance = new EnhancedMLTrainer();
    }
    return EnhancedMLTrainer.instance;
  }

  public async initialize(): Promise<void> {
    if (this.isInitialized) return;

    console.log('üöÄ Initializing Enhanced ML Trainer...');
    
    try {
      // Load all datasets
      await this.dataProcessor.loadAllDatasets();
      
      // Train all models
      await this.trainAllModels();
      
      this.isInitialized = true;
      console.log('‚úÖ Enhanced ML Trainer initialized successfully');
    } catch (error) {
      console.error('‚ùå Error initializing Enhanced ML Trainer:', error);
      throw error;
    }
  }

  private async trainAllModels(): Promise<void> {
    console.log('üéØ Training all wildfire prediction models...');
    
    const trainingResults: ModelTrainingResult[] = [];
    
    // Train different types of models
    const models = [
      { name: 'wildfire-risk-v3', type: 'risk' },
      { name: 'fire-spread-v2', type: 'spread' },
      { name: 'ignition-probability-v4', type: 'ignition' },
      { name: 'fire-intensity-v1', type: 'intensity' },
      { name: 'evacuation-urgency-v1', type: 'evacuation' }
    ];

    for (const modelConfig of models) {
      try {
        console.log(`üèãÔ∏è Training ${modelConfig.name}...`);
        const result = await this.trainModel(modelConfig.name, modelConfig.type);
        trainingResults.push(result);
        console.log(`‚úÖ ${modelConfig.name} trained with ${result.accuracy.toFixed(2)}% accuracy`);
      } catch (error) {
        console.error(`‚ùå Error training ${modelConfig.name}:`, error);
      }
    }

    // Log training summary
    this.logTrainingSummary(trainingResults);
  }

  private async trainModel(modelName: string, modelType: string): Promise<ModelTrainingResult> {
    const startTime = Date.now();
    
    // Get training dataset
    const dataset = this.dataProcessor.createTrainingDataset();
    const statistics = this.dataProcessor.getDataStatistics();
    
    // Split data into train/validation/test sets (70/15/15)
    const { trainFeatures, trainLabels, valFeatures, valLabels, testFeatures, testLabels } = 
      this.splitDataset(dataset.features, dataset.labels, 0.7, 0.15);
    
    // Create model based on type
    const model = this.createModel(modelType, trainFeatures[0].length);
    
    // Prepare training data
    const trainTensor = tf.tensor2d(trainFeatures);
    const trainLabelsTensor = tf.tensor2d(trainLabels.map(l => [l]));
    const valTensor = tf.tensor2d(valFeatures);
    const valLabelsTensor = tf.tensor2d(valLabels.map(l => [l]));
    
    // Compile model
    model.compile({
      optimizer: tf.train.adam(0.001),
      loss: 'binaryCrossentropy',
      metrics: ['accuracy']
    });
    
    // Train model
    const history = await model.fit(trainTensor, trainLabelsTensor, {
      epochs: 50,
      batchSize: 32,
      validationData: [valTensor, valLabelsTensor],
      callbacks: [
        tf.callbacks.earlyStopping({ patience: 10, restoreBestWeights: true }),
        tf.callbacks.reduceLROnPlateau({ factor: 0.5, patience: 5 })
      ],
      verbose: 0
    });
    
    // Evaluate on test set
    const testTensor = tf.tensor2d(testFeatures);
    const testLabelsTensor = tf.tensor2d(testLabels.map(l => [l]));
    const evaluation = model.evaluate(testTensor, testLabelsTensor) as tf.Scalar[];
    
    const accuracy = evaluation[1].dataSync()[0] * 100;
    const loss = evaluation[0].dataSync()[0];
    const trainingTime = Date.now() - startTime;
    
    // Save trained model
    const trainedModel: TrainedModel = {
      name: modelName,
      model,
      accuracy,
      features: this.getFeatureNames(modelType),
      version: '1.0.0',
      trainingDate: new Date().toISOString()
    };
    
    this.trainedModels.set(modelName, trainedModel);
    
    // Clean up tensors
    trainTensor.dispose();
    trainLabelsTensor.dispose();
    valTensor.dispose();
    valLabelsTensor.dispose();
    testTensor.dispose();
    testLabelsTensor.dispose();
    
    return {
      modelName,
      accuracy,
      loss,
      trainingTime,
      modelSize: model.countParams(),
      features: this.getFeatureNames(modelType),
      metadata: {
        totalSamples: dataset.metadata.totalSamples,
        trainingSamples: trainFeatures.length,
        validationSamples: valFeatures.length,
        testSamples: testFeatures.length,
        fireSamples: dataset.metadata.fireSamples,
        noFireSamples: dataset.metadata.noFireSamples
      }
    };
  }

  private createModel(modelType: string, inputSize: number): tf.LayersModel {
    const model = tf.sequential();
    
    switch (modelType) {
      case 'risk':
        // Deep neural network for risk assessment
        model.add(tf.layers.dense({ units: 128, activation: 'relu', inputShape: [inputSize] }));
        model.add(tf.layers.dropout({ rate: 0.3 }));
        model.add(tf.layers.dense({ units: 64, activation: 'relu' }));
        model.add(tf.layers.dropout({ rate: 0.2 }));
        model.add(tf.layers.dense({ units: 32, activation: 'relu' }));
        model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));
        break;
        
      case 'spread':
        // LSTM-based model for fire spread prediction
        model.add(tf.layers.dense({ units: 64, activation: 'relu', inputShape: [inputSize] }));
        model.add(tf.layers.dense({ units: 32, activation: 'relu' }));
        model.add(tf.layers.dense({ units: 16, activation: 'relu' }));
        model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));
        break;
        
      case 'ignition':
        // Gradient boosting inspired architecture
        model.add(tf.layers.dense({ units: 96, activation: 'relu', inputShape: [inputSize] }));
        model.add(tf.layers.batchNormalization());
        model.add(tf.layers.dropout({ rate: 0.4 }));
        model.add(tf.layers.dense({ units: 48, activation: 'relu' }));
        model.add(tf.layers.batchNormalization());
        model.add(tf.layers.dropout({ rate: 0.3 }));
        model.add(tf.layers.dense({ units: 24, activation: 'relu' }));
        model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));
        break;
        
      case 'intensity':
        // Regression model for fire intensity
        model.add(tf.layers.dense({ units: 64, activation: 'relu', inputShape: [inputSize] }));
        model.add(tf.layers.dense({ units: 32, activation: 'relu' }));
        model.add(tf.layers.dense({ units: 16, activation: 'relu' }));
        model.add(tf.layers.dense({ units: 1, activation: 'linear' }));
        break;
        
      case 'evacuation':
        // Multi-class classification for evacuation urgency
        model.add(tf.layers.dense({ units: 128, activation: 'relu', inputShape: [inputSize] }));
        model.add(tf.layers.dropout({ rate: 0.3 }));
        model.add(tf.layers.dense({ units: 64, activation: 'relu' }));
        model.add(tf.layers.dropout({ rate: 0.2 }));
        model.add(tf.layers.dense({ units: 32, activation: 'relu' }));
        model.add(tf.layers.dense({ units: 5, activation: 'softmax' })); // 5 urgency levels
        break;
        
      default:
        // Default architecture
        model.add(tf.layers.dense({ units: 64, activation: 'relu', inputShape: [inputSize] }));
        model.add(tf.layers.dense({ units: 32, activation: 'relu' }));
        model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));
    }
    
    return model;
  }

  private getFeatureNames(modelType: string): string[] {
    const baseFeatures = [
      'latitude', 'longitude', 'temperature', 'humidity', 'windSpeed', 'windDirection',
      'pressure', 'rainfall', 'FFMC', 'DMC', 'DC', 'ISI', 'brightness', 'frp',
      'seasonalRisk', 'droughtIndex', 'fireIntensity'
    ];
    
    switch (modelType) {
      case 'risk':
        return baseFeatures;
      case 'spread':
        return ['windSpeed', 'windDirection', 'temperature', 'humidity', 'FFMC', 'DMC', 'DC', 'ISI'];
      case 'ignition':
        return ['temperature', 'humidity', 'windSpeed', 'FFMC', 'DMC', 'DC', 'seasonalRisk', 'droughtIndex'];
      case 'intensity':
        return ['brightness', 'frp', 'temperature', 'windSpeed', 'FFMC', 'DC', 'fireIntensity'];
      case 'evacuation':
        return ['fireIntensity', 'windSpeed', 'temperature', 'humidity', 'seasonalRisk', 'droughtIndex'];
      default:
        return baseFeatures;
    }
  }

  private splitDataset(features: number[][], labels: number[], trainRatio: number, valRatio: number) {
    const totalSamples = features.length;
    const trainSize = Math.floor(totalSamples * trainRatio);
    const valSize = Math.floor(totalSamples * valRatio);
    
    // Shuffle data
    const shuffledIndices = tf.util.createShuffledIndices(totalSamples);
    
    const trainFeatures: number[][] = [];
    const trainLabels: number[] = [];
    const valFeatures: number[][] = [];
    const valLabels: number[] = [];
    const testFeatures: number[][] = [];
    const testLabels: number[] = [];
    
    for (let i = 0; i < totalSamples; i++) {
      const index = shuffledIndices[i];
      if (i < trainSize) {
        trainFeatures.push(features[index]);
        trainLabels.push(labels[index]);
      } else if (i < trainSize + valSize) {
        valFeatures.push(features[index]);
        valLabels.push(labels[index]);
      } else {
        testFeatures.push(features[index]);
        testLabels.push(labels[index]);
      }
    }
    
    return { trainFeatures, trainLabels, valFeatures, valLabels, testFeatures, testLabels };
  }

  private logTrainingSummary(results: ModelTrainingResult[]): void {
    console.log('\nüìä Training Summary:');
    console.log('='.repeat(60));
    
    let totalAccuracy = 0;
    let totalTrainingTime = 0;
    let totalModelSize = 0;
    
    results.forEach(result => {
      console.log(`${result.modelName}:`);
      console.log(`  Accuracy: ${result.accuracy.toFixed(2)}%`);
      console.log(`  Loss: ${result.loss.toFixed(4)}`);
      console.log(`  Training Time: ${(result.trainingTime / 1000).toFixed(1)}s`);
      console.log(`  Model Size: ${result.modelSize.toLocaleString()} parameters`);
      console.log(`  Samples: ${result.metadata.trainingSamples} train, ${result.metadata.validationSamples} val, ${result.metadata.testSamples} test`);
      console.log('');
      
      totalAccuracy += result.accuracy;
      totalTrainingTime += result.trainingTime;
      totalModelSize += result.modelSize;
    });
    
    console.log(`Average Accuracy: ${(totalAccuracy / results.length).toFixed(2)}%`);
    console.log(`Total Training Time: ${(totalTrainingTime / 1000).toFixed(1)}s`);
    console.log(`Total Model Parameters: ${totalModelSize.toLocaleString()}`);
    console.log('='.repeat(60));
  }

  public getTrainedModel(modelName: string): TrainedModel | undefined {
    return this.trainedModels.get(modelName);
  }

  public getAllTrainedModels(): TrainedModel[] {
    return Array.from(this.trainedModels.values());
  }

  public async predict(modelName: string, input: number[]): Promise<number> {
    const model = this.trainedModels.get(modelName);
    if (!model) {
      throw new Error(`Model ${modelName} not found`);
    }
    
    const inputTensor = tf.tensor2d([input]);
    const prediction = model.model.predict(inputTensor) as tf.Tensor;
    const result = prediction.dataSync()[0];
    
    inputTensor.dispose();
    prediction.dispose();
    
    return result;
  }

  public async batchPredict(modelName: string, inputs: number[][]): Promise<number[]> {
    const model = this.trainedModels.get(modelName);
    if (!model) {
      throw new Error(`Model ${modelName} not found`);
    }
    
    const inputTensor = tf.tensor2d(inputs);
    const predictions = model.model.predict(inputTensor) as tf.Tensor;
    const results = Array.from(predictions.dataSync());
    
    inputTensor.dispose();
    predictions.dispose();
    
    return results;
  }

  public getModelStatistics(): any {
    const models = this.getAllTrainedModels();
    const totalParameters = models.reduce((sum, model) => sum + model.model.countParams(), 0);
    const averageAccuracy = models.reduce((sum, model) => sum + model.accuracy, 0) / models.length;
    
    return {
      totalModels: models.length,
      totalParameters,
      averageAccuracy,
      models: models.map(model => ({
        name: model.name,
        accuracy: model.accuracy,
        parameters: model.model.countParams(),
        version: model.version,
        trainingDate: model.trainingDate
      }))
    };
  }

  public async saveModels(): Promise<void> {
    console.log('üíæ Saving trained models...');
    
    for (const [name, model] of this.trainedModels) {
      try {
        // In a real implementation, you would save to a cloud storage or local file system
        // For now, we'll just log the model info
        console.log(`‚úÖ Model ${name} ready for deployment`);
        console.log(`   - Accuracy: ${model.accuracy.toFixed(2)}%`);
        console.log(`   - Parameters: ${model.model.countParams().toLocaleString()}`);
        console.log(`   - Features: ${model.features.length}`);
      } catch (error) {
        console.error(`‚ùå Error saving model ${name}:`, error);
      }
    }
  }
}

export default EnhancedMLTrainer;
